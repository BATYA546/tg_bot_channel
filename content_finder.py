# content_finder.py
import logging
import requests
from datetime import datetime
import random
import hashlib
from bs4 import BeautifulSoup
import re
import json

logger = logging.getLogger(__name__)

class ContentFinder:
    def __init__(self, db_manager=None):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
        self.db_manager = db_manager
        self.post_hashes = set()
        self.load_existing_hashes()
        
        self.sources = [
            self.parse_science_news,
            self.parse_tech_news,
            self.parse_historical_facts,
            self.generate_ai_content
        ]

    def load_existing_hashes(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ö–µ—à–∏ –∏–∑ –ë–î –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏"""
        if self.db_manager:
            try:
                conn = self.db_manager.get_connection()
                cursor = conn.cursor()
                cursor.execute('SELECT title, content FROM found_content')
                existing_posts = cursor.fetchall()
                
                for title, content in existing_posts:
                    text = title + content
                    content_hash = hashlib.md5(text.encode()).hexdigest()
                    self.post_hashes.add(content_hash)
                    
                logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.post_hashes)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ö–µ—à–µ–π –∏–∑ –ë–î")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ö–µ—à–µ–π –∏–∑ –ë–î: {e}")

    def search_content(self, max_posts=3):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        logger.info("üîç –ù–∞—á–∏–Ω–∞—é –ø–æ–∏—Å–∫ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
        
        found_content = []
        attempts = 0
        max_attempts = 15  # –£–≤–µ–ª–∏—á–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
        
        while len(found_content) < max_posts and attempts < max_attempts:
            attempts += 1
            logger.info(f"üîç –ü–æ–ø—ã—Ç–∫–∞ {attempts}/{max_attempts}")
            
            for source in self.sources:
                try:
                    content_list = source()
                    if content_list:
                        for content in content_list:
                            if self.is_truly_unique_content(content) and len(found_content) < max_posts:
                                found_content.append(content)
                                content_hash = self.get_content_hash(content)
                                self.post_hashes.add(content_hash)
                                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –ø–æ—Å—Ç: {content['title'][:50]}...")
                            
                            if len(found_content) >= max_posts:
                                break
                
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ {source.__name__}: {e}")
                    continue
                
                if len(found_content) >= max_posts:
                    break
        
        logger.info(f"üéØ –ù–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤: {len(found_content)}")
        return found_content

    def is_truly_unique_content(self, content):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ —Ö–µ—à–∏ –∏ –ë–î"""
        content_hash = self.get_content_hash(content)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ –ø–∞–º—è—Ç–∏
        if content_hash in self.post_hashes:
            logger.info(f"üö´ –ü–æ—Å—Ç —É–∂–µ –≤ –ø–∞–º—è—Ç–∏: {content['title'][:30]}...")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ –ë–î
        if self.db_manager and self.is_content_in_db(content):
            logger.info(f"üö´ –ü–æ—Å—Ç —É–∂–µ –≤ –ë–î: {content['title'][:30]}...")
            return False
            
        return True

    def is_content_in_db(self, content):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            conn = self.db_manager.get_connection()
            cursor = conn.cursor()
            
            # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –ø–æ—Å—Ç—ã –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É
            cursor.execute('''
                SELECT id FROM found_content 
                WHERE title = %s OR content LIKE %s
            ''', (content['title'], f"%{content['title'][:50]}%"))
            
            result = cursor.fetchone()
            return result is not None
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ë–î: {e}")
            return False

    def get_content_hash(self, content):
        """–°–æ–∑–¥–∞–µ—Ç –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π —Ö–µ—à –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –Ω–∞—á–∞–ª–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –ª—É—á—à–µ–π —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
        text = content['title'] + content['summary'][:200]
        return hashlib.md5(text.encode()).hexdigest()

    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π...
    def parse_science_news(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –Ω–∞—É—á–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å—é"""
        try:
            # Naked Science
            url = "https://naked-science.ru"
            response = self.session.get(url, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            articles = []
            news_items = soup.find_all('article', class_='news')[:5]
            
            for item in news_items:
                try:
                    title_elem = item.find('h2') or item.find('a')
                    if not title_elem:
                        continue
                    
                    title = title_elem.get_text().strip()
                    
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø–æ—Å—Ç—ã
                    if not self.is_relevant_content(title):
                        continue
                    
                    # –ò—â–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
                    description_elem = item.find('p') or item.find('div', class_='description')
                    description = description_elem.get_text().strip() if description_elem else ""
                    
                    full_text = self.get_article_content(item)
                    formatted_post = self.format_science_post(title, full_text or description)
                    
                    articles.append({
                        'title': title,
                        'summary': formatted_post,
                        'category': 'science',
                        'url': url,
                        'image_url': self.get_science_image(),
                        'found_date': datetime.now()
                    })
                    
                except Exception as e:
                    continue
                    
            return articles
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ω–∞—É—á–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
            return []

    def is_relevant_content(self, text):
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        keywords = [
            '–ø–µ—Ä–≤—ã–π', '–ø–µ—Ä–≤–æ–µ', '–∏–∑–æ–±—Ä–µ—Ç–µ–Ω–∏–µ', '–æ—Ç–∫—Ä—ã—Ç–∏–µ', '—Ä–µ–≤–æ–ª—é—Ü–∏—è',
            '–ø—Ä–æ—Ä—ã–≤', '—Ä–µ–∫–æ—Ä–¥', '–∏—Å—Ç–æ—Ä–∏—è', '—Å–æ–∑–¥–∞–Ω', '—Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω',
            '–∑–∞–ø—É—â–µ–Ω', '–æ–±–Ω–∞—Ä—É–∂–µ–Ω', '–Ω–∞—É—á–Ω—ã–π', '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è', '–∏–Ω–Ω–æ–≤–∞—Ü',
            '–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π', '–≤–ø–µ—Ä–≤—ã–µ', '–Ω–æ–≤–∞—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è', '–ø—Ä–æ—Ä—ã–≤',
            '–Ω–æ–≤–∞—è —ç—Ä–∞', '–ø–µ—Ä–µ–ª–æ–º–Ω—ã–π –º–æ–º–µ–Ω—Ç', '–∑–Ω–∞–∫–æ–≤–æ–µ', '—ç–ø–æ—Ö–∞–ª—å–Ω–æ–µ'
        ]
        text_lower = text.lower()
        return any(keyword in text_lower for keyword in keywords)

# –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∫–ª–∞—Å—Å–∞ –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π...

def setup_content_finder(db_manager=None):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å –ø–µ—Ä–µ–¥–∞—á–µ–π db_manager"""
    return ContentFinder(db_manager)
